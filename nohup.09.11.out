/home/fac/cmh/.local/lib/python3.6/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.
  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)
/home/fac/cmh/.local/lib/python3.6/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.
  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)
2020-08-13 20:05:52,247 Hello! This is Joey-NMT.
2020-08-13 20:05:54.141250: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6
2020-08-13 20:05:54.164901: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvrtc.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/fac/cmh/lib:.:/home/fac/cmh
2020-08-13 20:05:54.165088: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-08-13 20:05:55,758 Total params: 11574272
2020-08-13 20:05:55,762 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2020-08-13 20:05:59,975 cfg.name                           : bam_to_fr_bpe_transformer
2020-08-13 20:05:59,975 cfg.data.src                       : bam
2020-08-13 20:05:59,976 cfg.data.trg                       : fr
2020-08-13 20:05:59,976 cfg.data.train                     : data/raw_fr_bam/train
2020-08-13 20:05:59,976 cfg.data.dev                       : data/raw_fr_bam/dev
2020-08-13 20:05:59,977 cfg.data.test                      : data/raw_fr_bam/test
2020-08-13 20:05:59,977 cfg.data.level                     : word
2020-08-13 20:05:59,978 cfg.data.lowercase                 : False
2020-08-13 20:05:59,978 cfg.data.max_sent_length           : 100
2020-08-13 20:05:59,978 cfg.data.src_voc_min_freq          : 0
2020-08-13 20:05:59,979 cfg.data.src_voc_limit             : 1000
2020-08-13 20:05:59,979 cfg.data.trg_voc_min_freq          : 0
2020-08-13 20:05:59,979 cfg.data.trg_voc_limit             : 1000
2020-08-13 20:05:59,980 cfg.testing.beam_size              : 5
2020-08-13 20:05:59,980 cfg.testing.alpha                  : 1.0
2020-08-13 20:05:59,981 cfg.training.random_seed           : 42
2020-08-13 20:05:59,981 cfg.training.optimizer             : adam
2020-08-13 20:05:59,981 cfg.training.normalization         : tokens
2020-08-13 20:05:59,982 cfg.training.adam_betas            : [0.9, 0.999]
2020-08-13 20:05:59,982 cfg.training.scheduling            : plateau
2020-08-13 20:05:59,983 cfg.training.patience              : 5
2020-08-13 20:05:59,983 cfg.training.learning_rate_factor  : 0.5
2020-08-13 20:05:59,983 cfg.training.learning_rate_warmup  : 1000
2020-08-13 20:05:59,984 cfg.training.decrease_factor       : 0.7
2020-08-13 20:05:59,984 cfg.training.loss                  : crossentropy
2020-08-13 20:05:59,984 cfg.training.learning_rate         : 0.0004
2020-08-13 20:05:59,985 cfg.training.learning_rate_min     : 1e-08
2020-08-13 20:05:59,985 cfg.training.weight_decay          : 0.0
2020-08-13 20:05:59,986 cfg.training.label_smoothing       : 0.2
2020-08-13 20:05:59,986 cfg.training.batch_size            : 1024
2020-08-13 20:05:59,986 cfg.training.batch_type            : token
2020-08-13 20:05:59,987 cfg.training.eval_batch_size       : 256
2020-08-13 20:05:59,987 cfg.training.eval_batch_type       : token
2020-08-13 20:05:59,988 cfg.training.batch_multiplier      : 1
2020-08-13 20:05:59,988 cfg.training.early_stopping_metric : eval_metric
2020-08-13 20:05:59,988 cfg.training.epochs                : 120
2020-08-13 20:05:59,989 cfg.training.validation_freq       : 40
2020-08-13 20:05:59,989 cfg.training.logging_freq          : 10
2020-08-13 20:05:59,990 cfg.training.eval_metric           : bleu
2020-08-13 20:05:59,990 cfg.training.model_dir             : models/bam_to_fr_bpe_transformer
2020-08-13 20:05:59,990 cfg.training.overwrite             : True
2020-08-13 20:05:59,991 cfg.training.shuffle               : True
2020-08-13 20:05:59,991 cfg.training.use_cuda              : True
2020-08-13 20:05:59,991 cfg.training.max_output_length     : 100128
2020-08-13 20:05:59,992 cfg.training.print_valid_sents     : [0, 1, 2, 3]
2020-08-13 20:05:59,992 cfg.training.keep_last_ckpts       : 3
2020-08-13 20:05:59,993 cfg.model.initializer              : xavier
2020-08-13 20:05:59,993 cfg.model.bias_initializer         : zeros
2020-08-13 20:05:59,993 cfg.model.init_gain                : 1.0
2020-08-13 20:05:59,994 cfg.model.embed_initializer        : xavier
2020-08-13 20:05:59,994 cfg.model.embed_init_gain          : 1.0
2020-08-13 20:05:59,995 cfg.model.tied_embeddings          : False
2020-08-13 20:05:59,995 cfg.model.tied_softmax             : True
2020-08-13 20:05:59,995 cfg.model.encoder.type             : transformer
2020-08-13 20:05:59,996 cfg.model.encoder.num_layers       : 6
2020-08-13 20:05:59,996 cfg.model.encoder.num_heads        : 4
2020-08-13 20:05:59,997 cfg.model.encoder.embeddings.embedding_dim : 256
2020-08-13 20:05:59,997 cfg.model.encoder.embeddings.scale : True
2020-08-13 20:05:59,997 cfg.model.encoder.embeddings.dropout : 0.2
2020-08-13 20:05:59,998 cfg.model.encoder.hidden_size      : 256
2020-08-13 20:05:59,998 cfg.model.encoder.ff_size          : 1024
2020-08-13 20:05:59,999 cfg.model.encoder.dropout          : 0.3
2020-08-13 20:05:59,999 cfg.model.decoder.type             : transformer
2020-08-13 20:06:00,000 cfg.model.decoder.num_layers       : 6
2020-08-13 20:06:00,000 cfg.model.decoder.num_heads        : 4
2020-08-13 20:06:00,000 cfg.model.decoder.embeddings.embedding_dim : 256
2020-08-13 20:06:00,001 cfg.model.decoder.embeddings.scale : True
2020-08-13 20:06:00,001 cfg.model.decoder.embeddings.dropout : 0.2
2020-08-13 20:06:00,002 cfg.model.decoder.hidden_size      : 256
2020-08-13 20:06:00,002 cfg.model.decoder.ff_size          : 1024
2020-08-13 20:06:00,002 cfg.model.decoder.dropout          : 0.3
2020-08-13 20:06:00,003 Data set sizes: 
	train 1611,
	valid 268,
	test 267
2020-08-13 20:06:00,003 First training example:
	[SRC] N'i binna ka bɔ jiri sanfɛ, i bolo bɛ se ka kari.
	[TRG] Si tu tombais d'un arbre, tu pourrais se casser le bras.
2020-08-13 20:06:00,004 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) ka (5) bɛ (6) ye (7) A (8) ? (9) I
2020-08-13 20:06:00,005 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) de (5) la (6) est (7) Il (8) le (9) à
2020-08-13 20:06:00,006 Number of Src words (types): 1004
2020-08-13 20:06:00,006 Number of Trg words (types): 1004
2020-08-13 20:06:00,007 Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=4),
	decoder=TransformerDecoder(num_layers=6, num_heads=4),
	src_embed=Embeddings(embedding_dim=256, vocab_size=1004),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=1004))
/home/fac/cmh/.local/lib/python3.6/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.
  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)
2020-08-13 20:06:00,040 EPOCH 1
/home/fac/cmh/.local/lib/python3.6/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.
  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)
/home/fac/cmh/.local/lib/python3.6/site-packages/joeynmt/loss.py:46: UserWarning: This overload of nonzero is deprecated:
	nonzero(Tensor input, *, Tensor out)
Consider using one of the following signatures instead:
	nonzero(Tensor input, *, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)
  padding_positions = torch.nonzero(targets.data == self.pad_index)
2020-08-13 20:06:01,124 Epoch   1 Step:       10 Batch Loss:     4.656417 Tokens per Sec:     3738, Lr: 0.000400
2020-08-13 20:06:02,035 Epoch   1 Step:       20 Batch Loss:     3.809261 Tokens per Sec:     5930, Lr: 0.000400
2020-08-13 20:06:02,218 Epoch   1: total training loss 87.73
2020-08-13 20:06:02,219 EPOCH 2
2020-08-13 20:06:02,967 Epoch   2 Step:       30 Batch Loss:     3.980788 Tokens per Sec:     4823, Lr: 0.000400
2020-08-13 20:06:03,888 Epoch   2 Step:       40 Batch Loss:     3.374647 Tokens per Sec:     5153, Lr: 0.000400
2020-08-13 20:06:04,707 Hooray! New best validation result [eval_metric]!
2020-08-13 20:06:04,708 Saving new checkpoint.
2020-08-13 20:06:11,032 Example #0
2020-08-13 20:06:11,033 	Source:     ji kalanman
2020-08-13 20:06:11,034 	Reference:  l'eau chaude
2020-08-13 20:06:11,034 	Hypothesis: <unk>
2020-08-13 20:06:11,035 Example #1
2020-08-13 20:06:11,035 	Source:     ni X ye
2020-08-13 20:06:11,036 	Reference:  avec X
2020-08-13 20:06:11,036 	Hypothesis: <unk>
2020-08-13 20:06:11,037 Example #2
2020-08-13 20:06:11,038 	Source:     Sɛ tɛ fɛn juguw yuguri ka bila a denw kɔrɔ.
2020-08-13 20:06:11,038 	Reference:  Un parent ne donne pas de mauvaises choses à son enfant.
2020-08-13 20:06:11,039 	Hypothesis: <unk>
2020-08-13 20:06:11,039 Example #3
2020-08-13 20:06:11,040 	Source:     jɛgɛ kɛnɛ
2020-08-13 20:06:11,040 	Reference:  poisson frais
2020-08-13 20:06:11,041 	Hypothesis: <unk>
2020-08-13 20:06:11,041 Validation result (greedy) at epoch   2, step       40: bleu:   0.00, loss: 5351.8159, ppl:  23.4660, duration: 7.1519s
2020-08-13 20:06:11,440 Epoch   2: total training loss 78.84
2020-08-13 20:06:11,441 EPOCH 3
2020-08-13 20:06:11,974 Epoch   3 Step:       50 Batch Loss:     3.720738 Tokens per Sec:     5532, Lr: 0.000400
2020-08-13 20:06:12,841 Epoch   3 Step:       60 Batch Loss:     3.691842 Tokens per Sec:     5588, Lr: 0.000400
2020-08-13 20:06:13,365 Epoch   3: total training loss 76.92
2020-08-13 20:06:13,366 EPOCH 4
2020-08-13 20:06:13,733 Epoch   4 Step:       70 Batch Loss:     3.729211 Tokens per Sec:     5538, Lr: 0.000400
2020-08-13 20:06:14,613 Epoch   4 Step:       80 Batch Loss:     3.792747 Tokens per Sec:     5125, Lr: 0.000400
2020-08-13 20:06:15,489 Example #0
2020-08-13 20:06:15,490 	Source:     ji kalanman
2020-08-13 20:06:15,490 	Reference:  l'eau chaude
2020-08-13 20:06:15,491 	Hypothesis: <unk>
2020-08-13 20:06:15,491 Example #1
2020-08-13 20:06:15,492 	Source:     ni X ye
2020-08-13 20:06:15,492 	Reference:  avec X
2020-08-13 20:06:15,493 	Hypothesis: <unk>
2020-08-13 20:06:15,493 Example #2
2020-08-13 20:06:15,494 	Source:     Sɛ tɛ fɛn juguw yuguri ka bila a denw kɔrɔ.
2020-08-13 20:06:15,494 	Reference:  Un parent ne donne pas de mauvaises choses à son enfant.
2020-08-13 20:06:15,495 	Hypothesis: <unk> <unk>
2020-08-13 20:06:15,495 Example #3
2020-08-13 20:06:15,496 	Source:     jɛgɛ kɛnɛ
2020-08-13 20:06:15,497 	Reference:  poisson frais
2020-08-13 20:06:15,497 	Hypothesis: <unk>
2020-08-13 20:06:15,497 Validation result (greedy) at epoch   4, step       80: bleu:   0.00, loss: 4972.9512, ppl:  18.7682, duration: 0.8833s
2020-08-13 20:06:16,116 Epoch   4: total training loss 71.23
2020-08-13 20:06:16,117 EPOCH 5
2020-08-13 20:06:16,387 Epoch   5 Step:       90 Batch Loss:     3.836658 Tokens per Sec:     5630, Lr: 0.000400
2020-08-13 20:06:17,260 Epoch   5 Step:      100 Batch Loss:     3.119994 Tokens per Sec:     5336, Lr: 0.000400
2020-08-13 20:06:17,957 Epoch   5: total training loss 69.08
2020-08-13 20:06:17,958 EPOCH 6
2020-08-13 20:06:18,141 Epoch   6 Step:      110 Batch Loss:     3.000906 Tokens per Sec:     4977, Lr: 0.000400
2020-08-13 20:06:19,017 Epoch   6 Step:      120 Batch Loss:     3.031948 Tokens per Sec:     5523, Lr: 0.000400
2020-08-13 20:06:22,939 Example #0
2020-08-13 20:06:22,940 	Source:     ji kalanman
2020-08-13 20:06:22,940 	Reference:  l'eau chaude
2020-08-13 20:06:22,940 	Hypothesis: <unk>
2020-08-13 20:06:22,941 Example #1
2020-08-13 20:06:22,941 	Source:     ni X ye
2020-08-13 20:06:22,942 	Reference:  avec X
2020-08-13 20:06:22,942 	Hypothesis: <unk>
2020-08-13 20:06:22,942 Example #2
2020-08-13 20:06:22,943 	Source:     Sɛ tɛ fɛn juguw yuguri ka bila a denw kɔrɔ.
2020-08-13 20:06:22,944 	Reference:  Un parent ne donne pas de mauvaises choses à son enfant.
2020-08-13 20:06:22,944 	Hypothesis: <unk> <unk> <unk> <unk> <unk>
2020-08-13 20:06:22,944 Example #3
2020-08-13 20:06:22,945 	Source:     jɛgɛ kɛnɛ
2020-08-13 20:06:22,945 	Reference:  poisson frais
2020-08-13 20:06:22,946 	Hypothesis: <unk>
2020-08-13 20:06:22,946 Validation result (greedy) at epoch   6, step      120: bleu:   0.00, loss: 4663.3809, ppl:  15.6369, duration: 3.9281s
2020-08-13 20:06:23,826 Epoch   6 Step:      130 Batch Loss:     2.805907 Tokens per Sec:     5212, Lr: 0.000400
2020-08-13 20:06:23,827 Epoch   6: total training loss 69.45
2020-08-13 20:06:23,828 EPOCH 7
2020-08-13 20:06:24,699 Epoch   7 Step:      140 Batch Loss:     3.253175 Tokens per Sec:     5590, Lr: 0.000400
2020-08-13 20:06:25,569 Epoch   7 Step:      150 Batch Loss:     3.363503 Tokens per Sec:     5150, Lr: 0.000400
2020-08-13 20:06:25,743 Epoch   7: total training loss 67.37
2020-08-13 20:06:25,744 EPOCH 8
2020-08-13 20:06:26,443 Epoch   8 Step:      160 Batch Loss:     3.022788 Tokens per Sec:     5277, Lr: 0.000400
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/fac/cmh/.local/lib/python3.6/site-packages/joeynmt/__main__.py", line 41, in <module>
    main()
  File "/home/fac/cmh/.local/lib/python3.6/site-packages/joeynmt/__main__.py", line 29, in main
    train(cfg_file=args.config_path)
  File "/home/fac/cmh/.local/lib/python3.6/site-packages/joeynmt/training.py", line 650, in train
    trainer.train_and_validate(train_data=train_data, valid_data=dev_data)
  File "/home/fac/cmh/.local/lib/python3.6/site-packages/joeynmt/training.py", line 375, in train_and_validate
    batch_type=self.eval_batch_type
  File "/home/fac/cmh/.local/lib/python3.6/site-packages/joeynmt/prediction.py", line 106, in validate_on_data
    max_output_length=max_output_length)
  File "/home/fac/cmh/.local/lib/python3.6/site-packages/joeynmt/model.py", line 170, in run_batch
    max_output_length=max_output_length)
  File "/home/fac/cmh/.local/lib/python3.6/site-packages/joeynmt/search.py", line 44, in greedy
    decoder, encoder_output, encoder_hidden)
  File "/home/fac/cmh/.local/lib/python3.6/site-packages/joeynmt/search.py", line 154, in transformer_greedy
    trg_mask=trg_mask
  File "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/fac/cmh/.local/lib/python3.6/site-packages/joeynmt/decoders.py", line 518, in forward
    src_mask=src_mask, trg_mask=trg_mask)
  File "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/fac/cmh/.local/lib/python3.6/site-packages/joeynmt/transformer_layers.py", line 264, in forward
    h1 = self.trg_trg_att(x_norm, x_norm, x_norm, mask=trg_mask)
  File "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/fac/cmh/.local/lib/python3.6/site-packages/joeynmt/transformer_layers.py", line 73, in forward
    scores = scores.masked_fill(~mask.unsqueeze(1), float('-inf'))
RuntimeError: CUDA out of memory. Tried to allocate 2.57 GiB (GPU 0; 7.43 GiB total capacity; 3.31 GiB already allocated; 2.58 GiB free; 4.26 GiB reserved in total by PyTorch)
/home/fac/cmh/.local/lib/python3.6/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.
  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)
/home/fac/cmh/.local/lib/python3.6/site-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.
  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)
2020-08-13 22:51:45,183 Hello! This is Joey-NMT.
2020-08-13 22:51:46.208337: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6
2020-08-13 22:51:46.226719: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvrtc.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/fac/cmh/lib:.:/home/fac/cmh
2020-08-13 22:51:46.226941: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-08-13 22:51:47,302 Total params: 11574272
2020-08-13 22:51:47,304 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2020-08-13 22:51:49,839 cfg.name                           : bam_to_fr_bpe_transformer
2020-08-13 22:51:49,839 cfg.data.src                       : bam
2020-08-13 22:51:49,840 cfg.data.trg                       : fr
2020-08-13 22:51:49,840 cfg.data.train                     : data/raw_fr_bam/train
2020-08-13 22:51:49,840 cfg.data.dev                       : data/raw_fr_bam/dev
2020-08-13 22:51:49,841 cfg.data.test                      : data/raw_fr_bam/test
2020-08-13 22:51:49,841 cfg.data.level                     : word
2020-08-13 22:51:49,842 cfg.data.lowercase                 : False
2020-08-13 22:51:49,842 cfg.data.max_sent_length           : 100
2020-08-13 22:51:49,843 cfg.data.src_voc_min_freq          : 0
2020-08-13 22:51:49,843 cfg.data.src_voc_limit             : 1000
2020-08-13 22:51:49,844 cfg.data.trg_voc_min_freq          : 0
2020-08-13 22:51:49,844 cfg.data.trg_voc_limit             : 1000
2020-08-13 22:51:49,845 cfg.testing.beam_size              : 5
2020-08-13 22:51:49,845 cfg.testing.alpha                  : 1.0
2020-08-13 22:51:49,845 cfg.training.random_seed           : 42
2020-08-13 22:51:49,846 cfg.training.optimizer             : adam
2020-08-13 22:51:49,846 cfg.training.normalization         : tokens
2020-08-13 22:51:49,847 cfg.training.adam_betas            : [0.9, 0.999]
2020-08-13 22:51:49,847 cfg.training.scheduling            : plateau
2020-08-13 22:51:49,848 cfg.training.patience              : 5
2020-08-13 22:51:49,848 cfg.training.learning_rate_factor  : 0.5
2020-08-13 22:51:49,849 cfg.training.learning_rate_warmup  : 1000
2020-08-13 22:51:49,849 cfg.training.decrease_factor       : 0.7
2020-08-13 22:51:49,850 cfg.training.loss                  : crossentropy
2020-08-13 22:51:49,850 cfg.training.learning_rate         : 0.0004
2020-08-13 22:51:49,851 cfg.training.learning_rate_min     : 1e-08
2020-08-13 22:51:49,851 cfg.training.weight_decay          : 0.0
2020-08-13 22:51:49,852 cfg.training.label_smoothing       : 0.2
2020-08-13 22:51:49,852 cfg.training.batch_size            : 256
2020-08-13 22:51:49,853 cfg.training.batch_type            : token
2020-08-13 22:51:49,853 cfg.training.eval_batch_size       : 64
2020-08-13 22:51:49,854 cfg.training.eval_batch_type       : token
2020-08-13 22:51:49,854 cfg.training.batch_multiplier      : 1
2020-08-13 22:51:49,855 cfg.training.early_stopping_metric : eval_metric
2020-08-13 22:51:49,855 cfg.training.epochs                : 120
2020-08-13 22:51:49,856 cfg.training.validation_freq       : 40
2020-08-13 22:51:49,856 cfg.training.logging_freq          : 10
2020-08-13 22:51:49,857 cfg.training.eval_metric           : bleu
2020-08-13 22:51:49,857 cfg.training.model_dir             : models/bam_to_fr_bpe_transformer
2020-08-13 22:51:49,857 cfg.training.overwrite             : True
2020-08-13 22:51:49,858 cfg.training.shuffle               : True
2020-08-13 22:51:49,858 cfg.training.use_cuda              : True
2020-08-13 22:51:49,859 cfg.training.max_output_length     : 100128
2020-08-13 22:51:49,859 cfg.training.print_valid_sents     : [0, 1, 2, 3]
2020-08-13 22:51:49,859 cfg.training.keep_last_ckpts       : 3
2020-08-13 22:51:49,860 cfg.model.initializer              : xavier
2020-08-13 22:51:49,860 cfg.model.bias_initializer         : zeros
2020-08-13 22:51:49,861 cfg.model.init_gain                : 1.0
2020-08-13 22:51:49,861 cfg.model.embed_initializer        : xavier
2020-08-13 22:51:49,861 cfg.model.embed_init_gain          : 1.0
2020-08-13 22:51:49,862 cfg.model.tied_embeddings          : False
2020-08-13 22:51:49,862 cfg.model.tied_softmax             : True
2020-08-13 22:51:49,863 cfg.model.encoder.type             : transformer
2020-08-13 22:51:49,863 cfg.model.encoder.num_layers       : 6
2020-08-13 22:51:49,863 cfg.model.encoder.num_heads        : 4
2020-08-13 22:51:49,864 cfg.model.encoder.embeddings.embedding_dim : 256
2020-08-13 22:51:49,864 cfg.model.encoder.embeddings.scale : True
2020-08-13 22:51:49,864 cfg.model.encoder.embeddings.dropout : 0.2
2020-08-13 22:51:49,865 cfg.model.encoder.hidden_size      : 256
2020-08-13 22:51:49,865 cfg.model.encoder.ff_size          : 1024
2020-08-13 22:51:49,865 cfg.model.encoder.dropout          : 0.3
2020-08-13 22:51:49,866 cfg.model.decoder.type             : transformer
2020-08-13 22:51:49,866 cfg.model.decoder.num_layers       : 6
2020-08-13 22:51:49,867 cfg.model.decoder.num_heads        : 4
2020-08-13 22:51:49,867 cfg.model.decoder.embeddings.embedding_dim : 256
2020-08-13 22:51:49,868 cfg.model.decoder.embeddings.scale : True
2020-08-13 22:51:49,868 cfg.model.decoder.embeddings.dropout : 0.2
2020-08-13 22:51:49,868 cfg.model.decoder.hidden_size      : 256
2020-08-13 22:51:49,869 cfg.model.decoder.ff_size          : 1024
2020-08-13 22:51:49,869 cfg.model.decoder.dropout          : 0.3
2020-08-13 22:51:49,870 Data set sizes: 
	train 1611,
	valid 268,
	test 267
2020-08-13 22:51:49,870 First training example:
	[SRC] N'i binna ka bɔ jiri sanfɛ, i bolo bɛ se ka kari.
	[TRG] Si tu tombais d'un arbre, tu pourrais se casser le bras.
2020-08-13 22:51:49,871 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) ka (5) bɛ (6) ye (7) A (8) ? (9) I
2020-08-13 22:51:49,872 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) de (5) la (6) est (7) Il (8) le (9) à
2020-08-13 22:51:49,873 Number of Src words (types): 1004
2020-08-13 22:51:49,874 Number of Trg words (types): 1004
2020-08-13 22:51:49,874 Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=4),
	decoder=TransformerDecoder(num_layers=6, num_heads=4),
	src_embed=Embeddings(embedding_dim=256, vocab_size=1004),
	trg_embed=Embeddings(embedding_dim=256, vocab_size=1004))
/home/fac/cmh/.local/lib/python3.6/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.
  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)
2020-08-13 22:51:49,902 EPOCH 1
/home/fac/cmh/.local/lib/python3.6/site-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.
  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)
/home/fac/cmh/.local/lib/python3.6/site-packages/joeynmt/loss.py:46: UserWarning: This overload of nonzero is deprecated:
	nonzero(Tensor input, *, Tensor out)
Consider using one of the following signatures instead:
	nonzero(Tensor input, *, bool as_tuple) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:766.)
  padding_positions = torch.nonzero(targets.data == self.pad_index)
2020-08-13 22:51:50,931 Epoch   1 Step:       10 Batch Loss:     4.112988 Tokens per Sec:     1355, Lr: 0.000400
2020-08-13 22:51:51,869 Epoch   1 Step:       20 Batch Loss:     3.323185 Tokens per Sec:     1521, Lr: 0.000400
2020-08-13 22:51:52,742 Epoch   1 Step:       30 Batch Loss:     3.737808 Tokens per Sec:     1548, Lr: 0.000400
2020-08-13 22:51:53,624 Epoch   1 Step:       40 Batch Loss:     3.871974 Tokens per Sec:     1494, Lr: 0.000400
2020-08-13 22:51:55,973 Hooray! New best validation result [eval_metric]!
2020-08-13 22:51:55,974 Saving new checkpoint.
2020-08-13 22:52:00,978 Example #0
2020-08-13 22:52:00,980 	Source:     ji kalanman
2020-08-13 22:52:00,981 	Reference:  l'eau chaude
2020-08-13 22:52:00,981 	Hypothesis: <unk>
2020-08-13 22:52:00,982 Example #1
2020-08-13 22:52:00,983 	Source:     ni X ye
2020-08-13 22:52:00,984 	Reference:  avec X
2020-08-13 22:52:00,984 	Hypothesis: <unk>
2020-08-13 22:52:00,985 Example #2
2020-08-13 22:52:00,986 	Source:     Sɛ tɛ fɛn juguw yuguri ka bila a denw kɔrɔ.
2020-08-13 22:52:00,987 	Reference:  Un parent ne donne pas de mauvaises choses à son enfant.
2020-08-13 22:52:00,987 	Hypothesis: <unk>
2020-08-13 22:52:00,988 Example #3
2020-08-13 22:52:00,989 	Source:     jɛgɛ kɛnɛ
2020-08-13 22:52:00,989 	Reference:  poisson frais
2020-08-13 22:52:00,990 	Hypothesis: <unk>
2020-08-13 22:52:00,990 Validation result (greedy) at epoch   1, step       40: bleu:   0.00, loss: 5353.7905, ppl:  23.4933, duration: 7.3628s
2020-08-13 22:52:02,030 Epoch   1 Step:       50 Batch Loss:     3.918118 Tokens per Sec:     1467, Lr: 0.000400
2020-08-13 22:52:03,059 Epoch   1 Step:       60 Batch Loss:     3.965564 Tokens per Sec:     1310, Lr: 0.000400
2020-08-13 22:52:04,099 Epoch   1 Step:       70 Batch Loss:     3.673762 Tokens per Sec:     1351, Lr: 0.000400
2020-08-13 22:52:04,519 Epoch   1: total training loss 274.09
2020-08-13 22:52:04,520 EPOCH 2
2020-08-13 22:52:05,145 Epoch   2 Step:       80 Batch Loss:     3.467243 Tokens per Sec:     1343, Lr: 0.000400
2020-08-13 22:52:08,443 Example #0
2020-08-13 22:52:08,444 	Source:     ji kalanman
2020-08-13 22:52:08,445 	Reference:  l'eau chaude
2020-08-13 22:52:08,445 	Hypothesis: Il <unk>
2020-08-13 22:52:08,446 Example #1
2020-08-13 22:52:08,447 	Source:     ni X ye
2020-08-13 22:52:08,447 	Reference:  avec X
2020-08-13 22:52:08,448 	Hypothesis: Il <unk>
2020-08-13 22:52:08,448 Example #2
2020-08-13 22:52:08,450 	Source:     Sɛ tɛ fɛn juguw yuguri ka bila a denw kɔrɔ.
2020-08-13 22:52:08,450 	Reference:  Un parent ne donne pas de mauvaises choses à son enfant.
2020-08-13 22:52:08,451 	Hypothesis: Il Il <unk>
2020-08-13 22:52:08,451 Example #3
2020-08-13 22:52:08,452 	Source:     jɛgɛ kɛnɛ
2020-08-13 22:52:08,453 	Reference:  poisson frais
2020-08-13 22:52:08,453 	Hypothesis: Il <unk>
2020-08-13 22:52:08,454 Validation result (greedy) at epoch   2, step       80: bleu:   0.00, loss: 5153.6904, ppl:  20.8788, duration: 3.3072s
2020-08-13 22:52:09,503 Epoch   2 Step:       90 Batch Loss:     3.811233 Tokens per Sec:     1335, Lr: 0.000400
2020-08-13 22:52:10,547 Epoch   2 Step:      100 Batch Loss:     3.548139 Tokens per Sec:     1321, Lr: 0.000400
2020-08-13 22:52:11,578 Epoch   2 Step:      110 Batch Loss:     3.389462 Tokens per Sec:     1321, Lr: 0.000400
2020-08-13 22:52:12,622 Epoch   2 Step:      120 Batch Loss:     3.008869 Tokens per Sec:     1281, Lr: 0.000400
2020-08-13 22:52:15,913 Example #0
2020-08-13 22:52:15,915 	Source:     ji kalanman
2020-08-13 22:52:15,915 	Reference:  l'eau chaude
2020-08-13 22:52:15,916 	Hypothesis: <unk>
2020-08-13 22:52:15,916 Example #1
2020-08-13 22:52:15,917 	Source:     ni X ye
2020-08-13 22:52:15,918 	Reference:  avec X
2020-08-13 22:52:15,918 	Hypothesis: Il <unk>
2020-08-13 22:52:15,919 Example #2
2020-08-13 22:52:15,920 	Source:     Sɛ tɛ fɛn juguw yuguri ka bila a denw kɔrɔ.
2020-08-13 22:52:15,920 	Reference:  Un parent ne donne pas de mauvaises choses à son enfant.
2020-08-13 22:52:15,921 	Hypothesis: <unk> <unk> <unk>
2020-08-13 22:52:15,921 Example #3
2020-08-13 22:52:15,922 	Source:     jɛgɛ kɛnɛ
2020-08-13 22:52:15,923 	Reference:  poisson frais
2020-08-13 22:52:15,923 	Hypothesis: Il <unk>
2020-08-13 22:52:15,924 Validation result (greedy) at epoch   2, step      120: bleu:   0.00, loss: 4896.5439, ppl:  17.9414, duration: 3.3000s
2020-08-13 22:52:17,219 Epoch   2 Step:      130 Batch Loss:     4.044011 Tokens per Sec:     1058, Lr: 0.000400
2020-08-13 22:52:18,503 Epoch   2 Step:      140 Batch Loss:     3.174155 Tokens per Sec:     1119, Lr: 0.000400
2020-08-13 22:52:19,441 Epoch   2: total training loss 251.61
2020-08-13 22:52:19,441 EPOCH 3
2020-08-13 22:52:19,551 Epoch   3 Step:      150 Batch Loss:     2.731245 Tokens per Sec:      925, Lr: 0.000400
2020-08-13 22:52:20,597 Epoch   3 Step:      160 Batch Loss:     3.965016 Tokens per Sec:     1282, Lr: 0.000400
2020-08-13 22:52:37,322 Example #0
2020-08-13 22:52:37,323 	Source:     ji kalanman
2020-08-13 22:52:37,324 	Reference:  l'eau chaude
2020-08-13 22:52:37,324 	Hypothesis: <unk>
2020-08-13 22:52:37,325 Example #1
2020-08-13 22:52:37,326 	Source:     ni X ye
2020-08-13 22:52:37,327 	Reference:  avec X
2020-08-13 22:52:37,327 	Hypothesis: Il a a a a a <unk>
2020-08-13 22:52:37,328 Example #2
2020-08-13 22:52:37,329 	Source:     Sɛ tɛ fɛn juguw yuguri ka bila a denw kɔrɔ.
2020-08-13 22:52:37,329 	Reference:  Un parent ne donne pas de mauvaises choses à son enfant.
2020-08-13 22:52:37,330 	Hypothesis: <unk> <unk> <unk> <unk> <unk>
2020-08-13 22:52:37,330 Example #3
2020-08-13 22:52:37,332 	Source:     jɛgɛ kɛnɛ
2020-08-13 22:52:37,332 	Reference:  poisson frais
2020-08-13 22:52:37,333 	Hypothesis: Il a a a <unk>
2020-08-13 22:52:37,333 Validation result (greedy) at epoch   3, step      160: bleu:   0.00, loss: 4750.0400, ppl:  16.4567, duration: 16.7356s
2020-08-13 22:52:38,370 Epoch   3 Step:      170 Batch Loss:     3.285296 Tokens per Sec:     1323, Lr: 0.000400
2020-08-13 22:52:39,412 Epoch   3 Step:      180 Batch Loss:     3.338915 Tokens per Sec:     1301, Lr: 0.000400
2020-08-13 22:52:40,450 Epoch   3 Step:      190 Batch Loss:     2.580233 Tokens per Sec:     1325, Lr: 0.000400
2020-08-13 22:52:41,486 Epoch   3 Step:      200 Batch Loss:     3.096226 Tokens per Sec:     1278, Lr: 0.000400
2020-08-13 22:52:49,210 Example #0
2020-08-13 22:52:49,211 	Source:     ji kalanman
2020-08-13 22:52:49,212 	Reference:  l'eau chaude
2020-08-13 22:52:49,212 	Hypothesis: <unk>
2020-08-13 22:52:49,213 Example #1
2020-08-13 22:52:49,214 	Source:     ni X ye
2020-08-13 22:52:49,214 	Reference:  avec X
2020-08-13 22:52:49,215 	Hypothesis: Il a a a a a a a a a a a a a a X
2020-08-13 22:52:49,215 Example #2
2020-08-13 22:52:49,216 	Source:     Sɛ tɛ fɛn juguw yuguri ka bila a denw kɔrɔ.
2020-08-13 22:52:49,217 	Reference:  Un parent ne donne pas de mauvaises choses à son enfant.
2020-08-13 22:52:49,217 	Hypothesis: <unk> <unk> <unk> <unk> <unk>
2020-08-13 22:52:49,218 Example #3
2020-08-13 22:52:49,219 	Source:     jɛgɛ kɛnɛ
2020-08-13 22:52:49,219 	Reference:  poisson frais
2020-08-13 22:52:49,220 	Hypothesis: Il <unk>
2020-08-13 22:52:49,220 Validation result (greedy) at epoch   3, step      200: bleu:   0.00, loss: 4574.6279, ppl:  14.8397, duration: 7.7321s
2020-08-13 22:52:50,273 Epoch   3 Step:      210 Batch Loss:     2.881804 Tokens per Sec:     1274, Lr: 0.000400
2020-08-13 22:52:51,311 Epoch   3 Step:      220 Batch Loss:     2.503648 Tokens per Sec:     1409, Lr: 0.000400
2020-08-13 22:52:51,832 Epoch   3: total training loss 238.81
2020-08-13 22:52:51,833 EPOCH 4
2020-08-13 22:52:52,357 Epoch   4 Step:      230 Batch Loss:     2.711510 Tokens per Sec:     1436, Lr: 0.000400
2020-08-13 22:52:53,380 Epoch   4 Step:      240 Batch Loss:     2.678968 Tokens per Sec:     1315, Lr: 0.000400
2020-08-13 22:53:02,653 Example #0
2020-08-13 22:53:02,654 	Source:     ji kalanman
2020-08-13 22:53:02,654 	Reference:  l'eau chaude
2020-08-13 22:53:02,655 	Hypothesis: <unk>
2020-08-13 22:53:02,655 Example #1
2020-08-13 22:53:02,656 	Source:     ni X ye
2020-08-13 22:53:02,657 	Reference:  avec X
2020-08-13 22:53:02,657 	Hypothesis: <unk>
2020-08-13 22:53:02,658 Example #2
2020-08-13 22:53:02,659 	Source:     Sɛ tɛ fɛn juguw yuguri ka bila a denw kɔrɔ.
2020-08-13 22:53:02,659 	Reference:  Un parent ne donne pas de mauvaises choses à son enfant.
2020-08-13 22:53:02,660 	Hypothesis: Il a a <unk>
2020-08-13 22:53:02,660 Example #3
2020-08-13 22:53:02,661 	Source:     jɛgɛ kɛnɛ
2020-08-13 22:53:02,662 	Reference:  poisson frais
2020-08-13 22:53:02,662 	Hypothesis: <unk>
2020-08-13 22:53:02,663 Validation result (greedy) at epoch   4, step      240: bleu:   0.00, loss: 4524.2192, ppl:  14.4051, duration: 9.2815s
2020-08-13 22:53:03,689 Epoch   4 Step:      250 Batch Loss:     3.347150 Tokens per Sec:     1270, Lr: 0.000400
2020-08-13 22:53:04,700 Epoch   4 Step:      260 Batch Loss:     2.524391 Tokens per Sec:     1378, Lr: 0.000400
2020-08-13 22:53:05,717 Epoch   4 Step:      270 Batch Loss:     2.537514 Tokens per Sec:     1334, Lr: 0.000400
2020-08-13 22:53:06,736 Epoch   4 Step:      280 Batch Loss:     2.757346 Tokens per Sec:     1260, Lr: 0.000400
Traceback (most recent call last):
  File "/usr/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/usr/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/home/fac/cmh/.local/lib/python3.6/site-packages/joeynmt/__main__.py", line 41, in <module>
    main()
  File "/home/fac/cmh/.local/lib/python3.6/site-packages/joeynmt/__main__.py", line 29, in main
    train(cfg_file=args.config_path)
  File "/home/fac/cmh/.local/lib/python3.6/site-packages/joeynmt/training.py", line 650, in train
    trainer.train_and_validate(train_data=train_data, valid_data=dev_data)
  File "/home/fac/cmh/.local/lib/python3.6/site-packages/joeynmt/training.py", line 375, in train_and_validate
    batch_type=self.eval_batch_type
  File "/home/fac/cmh/.local/lib/python3.6/site-packages/joeynmt/prediction.py", line 106, in validate_on_data
    max_output_length=max_output_length)
  File "/home/fac/cmh/.local/lib/python3.6/site-packages/joeynmt/model.py", line 170, in run_batch
    max_output_length=max_output_length)
  File "/home/fac/cmh/.local/lib/python3.6/site-packages/joeynmt/search.py", line 44, in greedy
    decoder, encoder_output, encoder_hidden)
  File "/home/fac/cmh/.local/lib/python3.6/site-packages/joeynmt/search.py", line 154, in transformer_greedy
    trg_mask=trg_mask
  File "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/fac/cmh/.local/lib/python3.6/site-packages/joeynmt/decoders.py", line 510, in forward
    x = self.pe(trg_embed)  # add position encoding to word embedding
  File "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py", line 722, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/fac/cmh/.local/lib/python3.6/site-packages/joeynmt/transformer_layers.py", line 159, in forward
    return emb + self.pe[:, :emb.size(1)]
RuntimeError: The size of tensor a (5001) must match the size of tensor b (5000) at non-singleton dimension 1
